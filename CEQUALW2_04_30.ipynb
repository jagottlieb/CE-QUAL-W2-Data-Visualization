{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os, argparse, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.polynomial import Polynomial\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse as parse_to_datetime\n",
    "import imageio\n",
    "import openpyxl\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## PROFILE PLOT ####################################   \n",
    "## User Input from excel config file\n",
    "\n",
    "#reading in user input from excel config excel file\n",
    "config_path = \"makeprofileplot_config.xlsx\" #Location of excel user file\n",
    "config = pd.read_excel(config_path, skiprows=2, engine='openpyxl', usecols='A:C', index_col=0, nrows=22) # Need to download openpyxl package to import xlsx\n",
    "print(config)\n",
    "skiprows = config.at['Skip Rows', config.columns[0]]\n",
    "x_label = config.at['X Label', config.columns[0]]\n",
    "x_min = config.at['X Axis (min, max)', config.columns[0]]\n",
    "x_max = config.at['X Axis (min, max)', config.columns[1]]\n",
    "y_label = config.at['Y Label', config.columns[0]]\n",
    "y_min = config.at['Y Axis (min, max)', config.columns[0]]\n",
    "y_max = config.at['Y Axis (min, max)', config.columns[1]]\n",
    "start_day = config.at['Julian Start Day', config.columns[0]]\n",
    "obsdatapath = config.at['File', config.columns[0]]\n",
    "obs_day_column_name = config.at['Date Column', config.columns[0]]\n",
    "obs_variable = config.at['Variable Name', config.columns[0]]\n",
    "obs_variable_units = config.at['Variable Units', config.columns[0]]\n",
    "obs_variable_column_name = config.at['Variable Column Name', config.columns[0]]\n",
    "obs_depth_column_name = config.at['Depth Column Name', config.columns[0]] \n",
    "obs_result_column_name = config.at['Result Column Name', config.columns[0]]\n",
    "obs_na_values = config.at['NA Values', config.columns[0]]\n",
    "figure_title = config.at['Figure Title', config.columns[0]]\n",
    "# NOTE: append \"_column_name\" to variables that store labels (names of columns)\n",
    "modpath = config.at['File', config.columns[1]]\n",
    "mod_day_column_name = config.at['Date Column', config.columns[1]]\n",
    "mod_variable = config.at['Variable Name', config.columns[1]]\n",
    "mod_variable_column_name = config.at['Variable Column Name', config.columns[1]]\n",
    "mod_depth_column_name = config.at['Depth Column Name', config.columns[1]] \n",
    "mod_result_column_name = config.at['Result Column Name', config.columns[1]]\n",
    "mod_na_values = config.at['NA Values', config.columns[1]]\n",
    "mod_variable_units = config.at['Variable Units', config.columns[1]]\n",
    "\n",
    "profileplotfolder = config.at['Profile Plots Folder', config.columns[0]] \n",
    "statsfolder = config.at['Statistic Output Folder', config.columns[0]]\n",
    "#print(obsdatapath, obs_day, obs_param, modpath, mod_day, mod_param, profileplotfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# Linux Compatibility - Directory Handler\n",
    "# #\n",
    "\n",
    "'''\n",
    "    Windows and Linux environments use different formats for directories. This section of code\n",
    "    takes existing paths and if in a linux environment, changes '\\' to '/'. Then, it checks if those\n",
    "    directories exist in the current folder, and if not, creates them.\n",
    "\n",
    "'''\n",
    "\n",
    "import platform\n",
    "import os\n",
    "\n",
    "# If not Windows, add working directory path to variable and change '\\'\n",
    "if platform.system() != 'Windows':\n",
    "    modpath = os.getcwd() + '/' + modpath.replace('\\\\', '/') \n",
    "    obsdatapath = os.getcwd() + '/' + obsdatapath.replace('\\\\', '/') \n",
    "    profileplotfolder = os.getcwd() + '/' + profileplotfolder.replace('\\\\', '/')\n",
    "    statsfolder = os.getcwd() + '/' + statsfolder.replace('\\\\', '/')\n",
    "\n",
    "# For consiser code, added path lists to a List/Array to go through in a for loop\n",
    "path_list = [modpath, obsdatapath, profileplotfolder, statsfolder]\n",
    "\n",
    "# If directories for paths dont exist, create them\n",
    "if platform.system() != 'Windows':\n",
    "    dir_split = '/'\n",
    "else:\n",
    "    dir_split = '\\\\'\n",
    "\n",
    "for variable in path_list:\n",
    "    build_path = ''\n",
    "    path = variable.split(os.getcwd() + dir_split)[1].split(dir_split) # split path into array\n",
    "    if '.' in path[-1]:\n",
    "        path.pop() # Remove filename from end (Note: only works if file extension exists on end of filename)\n",
    "    for directory in path:\n",
    "        build_path += directory + dir_split\n",
    "        if not os.path.isdir(build_path):\n",
    "            os.mkdir(build_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in model and observed data\n",
    "\n",
    "print('loading model \"%s\"' % modpath)\n",
    "print('loading observed \"%s\"' % obsdatapath)\n",
    "\n",
    "#read in profile model outputs\n",
    "moddata = pd.read_csv(modpath, na_values=mod_na_values)\n",
    "\n",
    "#observed data\n",
    "obsdata = pd.read_csv(obsdatapath, na_values= obs_na_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditional Statements - Create tables for observed and modeled data\n",
    "#### This requires data to be in a specific format ####\n",
    "#Create model data table, round down days\n",
    "profobs = obsdata[(obsdata['Site'] == 'V - Hagg Lake')].copy() # conditions data to only include Site V, makes a copy so we dont alter obs data\n",
    "profobs = profobs[(profobs[obs_variable_column_name] == obs_variable)]\n",
    "profobs = profobs[[obs_day_column_name, obs_depth_column_name, obs_result_column_name]] #making a table with day, depth, and results\n",
    "profobs[obs_day_column_name] = profobs[obs_day_column_name].apply(np.floor) #round down\n",
    "profobs = profobs.dropna()\n",
    "\n",
    "#Create observed data table, round down days\n",
    "profmod = moddata[(moddata[mod_variable_column_name] == mod_variable)].copy() \n",
    "profmod = profmod[[mod_day_column_name, mod_depth_column_name, mod_result_column_name]]\n",
    "profmod[mod_day_column_name] = profmod[mod_day_column_name].apply(np.floor)\n",
    "profmod = profmod.dropna()\n",
    "\n",
    "#use this if you want to see the data\n",
    "#print('Observed data:')\n",
    "#print(profobs)\n",
    "#print('Model data:')\n",
    "#print(profmod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model days and observed days into a se\n",
    "modeldays = set(profmod[mod_day_column_name])\n",
    "observeddays = set(profobs[obs_day_column_name])\n",
    "days =  modeldays.intersection(observeddays) #find the ones that are in both data sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Index of Days in Model Dataset - In the future we may need to check that observed and modeled days match earlier in code\n",
    "#mod_ind = profmod_complete[mod_day].unique() # prof mod complete not defined\n",
    "#mod_ind #Index of Julian Days for model dataset. We are assuming the model days match the observed days.\n",
    "\n",
    "# renaming variables so they specify that they are interpolated!\n",
    "interpolated_df_day_column_name = mod_day_column_name\n",
    "interpolated_df_depth_column_name = 'Depth' #mod_depth_column_name\n",
    "interpolated_df_mod_result_column_name = mod_result_column_name\n",
    "interpolated_df_obs_result_column_name = obs_result_column_name\n",
    "interpolated_columns = [\n",
    "    interpolated_df_day_column_name, \n",
    "    interpolated_df_depth_column_name, \n",
    "    interpolated_df_mod_result_column_name, \n",
    "    interpolated_df_obs_result_column_name,\n",
    "]\n",
    "\n",
    "\n",
    "interpolated_df = pd.DataFrame(columns=interpolated_columns) #creating an empty data frame to put all of the interpolated values in\n",
    "\n",
    "#Interpolate - each days values are interpolated using this loop\n",
    "\n",
    "for i in days: # changed this to modeldays instead of mod_ind\n",
    "    profmod_i = profmod[(profmod[mod_day_column_name] == i)]\n",
    "    profobs_i = profobs[(profobs[obs_day_column_name] == i)]\n",
    "    \n",
    "    mod_depths = profmod_i[mod_depth_column_name]\n",
    "    mod_results = profmod_i[mod_result_column_name]\n",
    "    \n",
    "    obs_depths = profobs_i[obs_depth_column_name]\n",
    "    obs_results = profobs_i[obs_result_column_name]\n",
    "\n",
    "    # if there are no observed depths for day \"i\" np.interp will crash below. \n",
    "    # so, if there are none, skip this day (via \"continue\")\n",
    "    # if len(obs_depths) == 0:\n",
    "    #     print('no observed depths for day {}'.format(i))\n",
    "    #     continue\n",
    "    \n",
    "    interp_mod_results = list(np.interp(obs_depths, mod_depths, mod_results))\n",
    "    interp_mod_days = [i] * len(obs_depths)\n",
    "    interpolated_df = pd.concat([\n",
    "        interpolated_df, \n",
    "        pd.DataFrame(zip(interp_mod_days, obs_depths, interp_mod_results, obs_results), columns=interpolated_columns)\n",
    "    ])\n",
    "\n",
    "# new data frame will have day, depth, interpolated model data, observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Caluclate Statistic Values\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "stats_columns = [\n",
    "    'DAY',\n",
    "    'MAE', \n",
    "    'RMSE', \n",
    "    'ME',\n",
    "    'MODEL ST.DEV',\n",
    "    'PBIAS',\n",
    "    'MOD_MEAN',\n",
    "    'OBS_MEAN',\n",
    "]\n",
    "def make_empty_statsdf():\n",
    "    return pd.DataFrame(columns=stats_columns)\n",
    "\n",
    "def concat_statsdf(statsdf, df, day):\n",
    "    y_true = df[interpolated_df_obs_result_column_name].to_numpy()\n",
    "    y_pred = df[interpolated_df_mod_result_column_name].to_numpy()\n",
    "    MOD_MEAN = y_pred.mean()\n",
    "    OBS_MEAN = y_true.mean()\n",
    "    RMSE = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    ME = np.sum(y_pred - y_true) / len(y_true)\n",
    "    MAE = np.sum(np.absolute(y_pred - y_true))/ len(y_true)\n",
    "    MOD_ST_DEV = y_pred.std()\n",
    "    PBIAS = 100 * np.sum(y_true - y_pred) / np.sum(y_true)\n",
    "    return pd.concat([\n",
    "        statsdf,\n",
    "        pd.DataFrame([[day, MAE, RMSE, ME,MOD_ST_DEV, PBIAS, MOD_MEAN, OBS_MEAN]], columns=stats_columns)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the interpolated_df we created above\n",
    "#creating the profile plots\n",
    "\n",
    "statsdf = make_empty_statsdf()\n",
    "\n",
    "for i in days:\n",
    "    interp_i = interpolated_df[(interpolated_df[interpolated_df_day_column_name] == i)]\n",
    "    mod_i = profmod[(profmod[mod_day_column_name]==i)]\n",
    "    depths = list(interp_i[interpolated_df_depth_column_name])\n",
    "    mod_depths = list(mod_i[mod_depth_column_name])\n",
    "    x_mod = list(mod_i[mod_result_column_name])\n",
    "    x_obs = list(interp_i[interpolated_df_obs_result_column_name])\n",
    "    date = (start_day) + timedelta(days=(i-1))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_mod, mod_depths, marker = '', linestyle ='-', label = 'Model')\n",
    "    ax.plot(x_obs, depths, marker ='*', linestyle = 'None', color ='g', label = 'Observed')\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    ##\n",
    "    # Replace plt with specific figure/axis\n",
    "    ##\n",
    "\n",
    "    # plt.title(f\"{figure_title} {date.strftime('%B %d %Y')}\" )\n",
    "    # plt.xlabel(x_label)\n",
    "    # plt.ylabel(y_label)\n",
    "    # plt.legend(loc = 'lower right')\n",
    "\n",
    "    fig.suptitle(f\"{figure_title} {date.strftime('%B %d %Y')}\" )\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend(loc = 'lower right')\n",
    "    ############################################################\n",
    "\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "    ax.invert_yaxis()\n",
    "    ax.axis([x_min, x_max, y_max, y_min])\n",
    "    ax.text( 1, 2 , f\"Julian Day: {i}\")\n",
    "    plotname = f'profmod_{i}.jpg'\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    ##\n",
    "    # Catch .jpg error and retry as .png\n",
    "    ##\n",
    "\n",
    "    #fig.savefig(os.path.join(profileplotfolder, plotname))\n",
    "    \n",
    "    # Attempt to save as a .jpg, else save as a .png\n",
    "    try:\n",
    "        fig.savefig(os.path.join(profileplotfolder, plotname))\n",
    "    except ValueError:\n",
    "        print('ERROR: Unable to save as .jpg, saving as .png instead')\n",
    "        plotname = plotname.split('.')\n",
    "        plotname.pop()\n",
    "        plotname.append('png') # Throw away the file extension\n",
    "        plotname = '.'.join(plotname)\n",
    "        fig.savefig(os.path.join(profileplotfolder, plotname), format='png')\n",
    "    except:\n",
    "        print(f'Error: Unable to save {plotname}')\n",
    "    ############################################################\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    ##\n",
    "    # Fix runtime error for 20+ open plots\n",
    "    ##\n",
    "\n",
    "    #fig.clf()\n",
    "    plt.close()\n",
    "    ############################################################\n",
    "\n",
    "    statsdf = concat_statsdf(statsdf, interp_i, i).sort_values('DAY') # calling the statistics function in this loop to calculate for everyday\n",
    "\n",
    "    \n",
    "statsdf = concat_statsdf(statsdf, interpolated_df, 'AVG') #average statistics values\n",
    "statsdf.to_csv(os.path.join(statsfolder, 'Statistics.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gif of profile plots (Cui Yong, 2020)\n",
    "from pathlib import Path\n",
    "\n",
    "############################################################\n",
    "\n",
    "##\n",
    "# Function for parsing day out of file names to later assist with sorting\n",
    "##\n",
    "\n",
    "import re\n",
    "\n",
    "def numericalSort(raw):\n",
    "    ''' \n",
    "        Takes a string, splits out the numbers, converts to an int, and returns results for sorting\n",
    "        [Source: https://stackoverflow.com/questions/12093940/reading-files-in-a-particular-order-in-python]\n",
    "        Args:\n",
    "            value (string): value to be split\n",
    "        Return:\n",
    "            parts (List): string parts, seperated on number\n",
    "    '''\n",
    "    value = str(raw)\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    if len(parts) > 3:\n",
    "        return parts[3]\n",
    "    else:\n",
    "        return float('inf')  # Non-standard naming scheme - place file at end of gif\n",
    "\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')  # Regex for seperating numbers from strings\n",
    "############################################################\n",
    "\n",
    "image_path = Path(profileplotfolder)\n",
    "\n",
    "############################################################\n",
    "\n",
    "##\n",
    "# Read in files and sort them according to day. If no .jpg files exist, look for .png files\n",
    "##\n",
    "\n",
    "# images = list(image_path.glob('*.jpg'))\n",
    "\n",
    "images = []\n",
    "\n",
    "for file in sorted(list(image_path.glob('*.jpg')), key=numericalSort):\n",
    "    images.append(file)\n",
    "\n",
    "if len(images) == 0:\n",
    "    for file in sorted(list(image_path.glob('*.png')), key=numericalSort):\n",
    "        images.append(file)\n",
    "############################################################\n",
    "\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "\n",
    "len(image_list)\n",
    "imageio.mimwrite(os.path.join(profileplotfolder, 'profileplots.gif'), image_list , fps =4)\n",
    "file_name"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ffde3392ae05be31717657bd455cdead828e7e5629cab5edd84d959f2fee0f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
